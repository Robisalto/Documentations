---
title: POEI DevOps - ELK Stack
author: David DEBRAY
date: 2021-08-13
linkcolor: lightblue
pdf-engine: xelatex
header-includes:
 - \usepackage[margin=.5in]{geometry}
classoption: "12pt"
extensions: 'extra'
---
<link rel="icon" href="favicon.png" type="image/png" />
<meta name="viewport" content="width=device-width, initial-scale=1.0">

---

#### Introduction

Formateur: **Alexandre Chaussier**

- Mail: <a.chaussier@infopen.pro>
- Tél: [06.63.73.54.92](06.63.73.54.92)

2e partie de 3 formations:

- Terraform
- Prometheus & Grafana
- **ELK Stack** 

---

# Documentations
## Site Officiel

- <https://www.elastic.co/fr/what-is/elk-stack>


  ![](https://www.elastic.co/static-res/images/elk/elk-stack-elkb-diagram.svg)



> Alors, qu'est-ce que la Suite  ELK ? "ELK" est un acronyme pour trois projets en open source : Elasticsearch, Logstash et Kibana. Elasticsearch est un moteur de recherche et d'analyse. Logstash est un pipeline côté serveur, destiné au traitement des données (type ETL). Sa mission ? Ingérer simultanément des données provenant de multitude de sources, puis les transformer et les envoyer vers un système de stockage comme Elasticsearch. Kibana permet aux utilisateurs de visualiser des données avec des tableaux et des graphes dans Elasticsearch.
> 
> La Suite Elastic est l'évolution suivante de la Suite ELK


![](https://static-www.elastic.co/v3/assets/bltefdd0b53724fa2ce/blt58ea9362fd6aaad9/5c11ee47928f832d782d0628/elk-stack-social-ads-counseling.svg)

## Online Docs

## Doc Source
<!-- <iframe src="2021-08-16-POEI-ELK/"></iframe> -->


---

# Introduction
## Introduction
<iframe src="2021-08-16-POEI-ELK/introduction.html"></iframe>


# La Stack Elastic - Bases
## Installation & Composant
<iframe src="2021-08-16-POEI-ELK/installation.html"></iframe>

## Atelier 1
Atelier 1 - ES & Kibana
Installation d'Elasticsearch & Kibana

Le but est de déployer les premiers services avec lesquels nous allons travailler

- Créer une recette de déploiement Docker Compose pour déployer une instance de Kibana et d'Elasticsearch
- Valider que Kibana ait accès à Elasticsearch
- Aller dans le menu "Management / Dev Tools"
- Executer cette requête "`GET /_cat/health`" (cliquer sur "play" pour exécuter)




## Elasticsearch - Partie 1
<iframe src="2021-08-16-POEI-ELK/elasticsearch-concepts-1.html"></iframe>

### QCM 1
<iframe src="2021-08-16-POEI-ELK/QCM - Elasticsearch - Partie 1 Attempt review.html"></iframe>


## Elasticsearch - Partie 2
<iframe src="2021-08-16-POEI-ELK/elasticsearch-concepts-2.html"></iframe>

### QCM 2
<iframe src="2021-08-16-POEI-ELK/QCM - Elasticsearch - Partie 2 Attempt review.html"></iframe>


## Atelier 2

Pour simplifier les manipulations, utilisez la console developpeur de Kibana pour executer vos requêtes
Création de données

- Créer un index nommé test01
- Vérifier que cet index est maintenant présent
- Créer ce document dans cet index
    {
      "titre": "Premier document",
      "description": "C'est la première fois que je crée un document dans ES.",
      "quantité": 12,
      "date_creation": "18-10-2020"
    }
- Afficher ce document
- Afficher quel mapping a été appliqué par défaut. Est-il optimal ?
- Essayer de modifier le mapping pour le champ date_creation, pour un plus adapté
- Créer un nouvel index test02
- Appliquer un mapping plus adapté aux données du document ci-dessus
- Afficher la manière dont le texte de la description du document a été traité par l'analyzer
- Créer un index test03 qui :
  - intègre le mapping ci-dessus
  - indexera la description sans l'altérer
  - indexera la description en supprimant les mots sans valeur ajoutée
- Faire un import multiple de 4 documents en une seule requête

### Atelier 2 - Correction


#### Question 1

```KQL=
PUT /test01
```

#### Question 2
```KQL
GET /_cat/indices
```

#### Question 3

```KQL
POST /test01/_doc/1
{
  "titre": "Premier document",
  "description": "C'est la première fois que je crée un document dans ES.",
  "quantité": 12,
  "date_creation": "18-10-2020"
}

```

#### Question 4

```KQL
GET /test01/_doc/1

```

#### Question 5

```KQL
GET /test01/_mapping
GET /test01/?pretty


```

Non, il n'est pas optimal car la date est considérée comme du text.


#### Question 6

```KQL
POST /test01/_mapping
{
  "properties": {
    "date_creation": {
      "type": "date"
    }
  }
}

```

Il n'est pas possible de changer le mapping d'un champ existant, il faut recréer un nouvel index avec le bon mapping.

#### Question 7

```KQL
PUT /test02

```


#### Question 8

```KQL
POST /test02/_mapping
{
  "properties": {
    "titre": {
      "type": "text",
      "fields" : {
        "keyword" : {
          "type" : "keyword",
          "ignore_above" : 256
        }
      }
    },
    "description": {
      "type": "text"
    },
    "quantité": {
      "type": "long"
    },
    "date_creation": {
      "type": "date",
      "format": "dd-MM-yyy"
    }
  }
}

```

#### Question 9

```KQL
GET /test02/_analyze
{
  "text": "C'est la première fois que je crée un document dans ES."
}

```


#### Question 10

```KQL
PUT /test03/
{
  "settings": {
    "analysis": {
      "analyzer": {
        "std_fr": {
          "type":      "standard",
          "stopwords": "_french_"
        }
      }
    }
  },
  "mappings": {
    "properties": {
      "titre": {
        "type": "text",
        "fields" : {
          "keyword" : {
            "type" : "keyword",
            "ignore_above" : 256
          }
        }
      },
      "description": {
        "type": "text",
        "analyzer": "standard",
        "fields": {
          "fr": {
            "type":     "text",
            "analyzer": "std_fr"
          }
        }
      },
      "quantité": {
        "type": "long"
      },
      "date_creation": {
        "type": "date",
        "format": "dd-MM-yyy"
      }
    }
  }
}

GET /test03/_analyze
{
  "field": "description.fr",
  "text": "C'est la première fois que je crée un document dans ES."
}

```


#### Question 11

```KQL
POST /test03/_bulk
{"create": {"_id": 1}}
{"titre": "Premier document", "description": "C'est la première fois que je crée un document dans ES.", "quantité": 12, "date_creation": "18-10-2020"}
{"create": {"_id": 2}}
{"titre": "Deuxième document", "description": "C'est la deuxième fois que je crée un document dans ES.", "quantité": 100, "date_creation": "19-10-2020"}
{"create": {"_id": 3}}
{"titre": "Troisième document", "description": "C'est la troisième fois que je crée un document dans ES.", "quantité": 18, "date_creation": "18-11-2020"}
{"create": {"_id": 4}}
{"titre": "Quatrième document", "description": "C'est la quatrième fois que je crée un document dans ES.", "quantité": 32, "date_creation": "18-12-2020"}

```


### QCM - Requêtes Elasticsearch

<iframe src="2021-08-16-POEI-ELK/QCM - Requêtes Elasticsearch Attempt review.html"></iframe>



## Logstash
<iframe src="2021-08-16-POEI-ELK/logstash.html"></iframe>

### QCM - Logstash
<iframe src="2021-08-16-POEI-ELK/QCM - Logstash Attempt review.html.html"></iframe>


### Atelier 3 Logstash
Atelier 3 - Mise en place de Logstash

- Ajouter un container logstash dans la stack docker-compose existante
- Démarrer dans la stack un container ubuntu, dont le dossier /var/log sera un- volume qui sera également monté dans le container logstash
- Dans ce container, installer rsyslog et rendre le fichier /var/log/syslog lisible- par tout le monde
- Ajouter une configuration à Logstash pour suivre le contenu de ce fichier et- afficher le contenu traité sur stdout
- Tester en utilisant la commande logger dans le conteneur ubuntu pour générer du- contenu
- Configurer logstash pour envoyer les données à Elasticsearch
- Vérifier qu'un index a bien été créé dans Elasticsearch
- Créer un index kibana
- Vérifier que les données sont disponibles depuis Kibana
- Intégrer Filebeat dans la stack pour faire remonter les logs dans Elasticsearch
- Créer un index Kibana pour visualiser ces informations
- Depuis Logstash, exporter le contenu de l'index qui contient les entrées de log dans un CSV



# Administration & Scalabilité

<iframe src="2021-08-16-POEI-ELK/administration-scalabilite.html"></iframe>

## QCM

<iframe src="2021-08-16-POEI-ELK/QCM - Administration & scalabilité Attempt review.html"></iframe>


## Atelier
Atelier 4

- Créer un cluster Elasticsearch de 3 noeuds, nommés elasticsearch01, elasticsearch02, elasticsearch03
- Charger toutes les données de test de la stack
- Créer un snapshot de ces nouveaux index dans un volume dédié

### Correction

<iframe src="2021-08-16-POEI-ELK/Correction exercice/"></iframe>



---

# *Tips & Tricks*

## Documentations réseau

- <https://tls.ulfheim.net/>
- <https://www.frameip.com/>
